---
title: "Analyse de l'enquête Bioinfo-fr.net"
output:
  prettydoc::html_pretty:
    theme: cayman
---

<!-- <style type="text/css"> -->
<!-- .inner { -->
<!--   width: 90%; -->
<!-- } -->
<!-- </style> -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Header redifinition
cn_enq <- c(
  "age",
  "gender",
  "diplome",
  "major_field",
  "year_exp",
  "year_foreign",
  "current_loc",
  "public_private",
  "contract",
  "nb_bio_with",
  "nb_bioinfo_with",
  "nb_other_with",
  "position_title",
  "salary",
  "OS",
  "prog_language",
  "lang_dev_web",
  "lang_bdd",
  "lang_scripting",
  "lang_stats_anal",
  "lang_sys_admin",
  "lang_app_dev",
  "lang_other"
)

# Loading data
df_enq_raw <- read.table("data/questionnaire_bioinfo_fr_2018.tsv", 
                    skip = 2, 
                    header = TRUE, 
                    encoding = "UTF-8", 
                    check.names = FALSE, 
                    col.names = cn_enq)
df_enq_raw <- cbind(id = 1:nrow(df_enq_raw), df_enq_raw)

# Creating output dir
dir.create("plots", showWarnings = FALSE)

# libraries
library(dplyr)
library(ggplot2)
library(gridExtra)
library(tm)
library(textcat)
library(wordcloud)
# library(DT)
```

```{r logo, out.height = "150px", fig.align='center', echo=FALSE}
knitr::include_graphics("img/logo_bioinfofr.png")
```

## Contexte
Enquête bioinfo-fr 2018 afin de dresser un portrait des bioinformaticiens en France

## Nettoyage des abérations
Afin de filtrer les réponses hors de propos on va effectuer un premier tri sur les données par le biais des données numériques
```{r numeric_filter}
summary(df_enq_raw$year_exp)
summary(df_enq_raw$year_foreign)
summary(df_enq_raw$nb_bio_with)
summary(df_enq_raw$nb_bioinfo_with)
summary(df_enq_raw$nb_other_with)

# Removing entry which have
#   - more than 60 year exp or foreign (because of retirement max)
#   - more than 2.5 z-score (according to ‘thumb-rule’ thresholds)

df_enq = df_enq_raw %>%
  filter(year_exp < 60) %>%
  filter(year_foreign < 60) %>%
  filter(year_exp + year_foreign < 60) %>%
  filter(scale(nb_bio_with) < 3) %>%
  filter(scale(nb_bioinfo_with) < 3) %>%
  filter(scale(nb_other_with) < 3) %>%
  filter(scale(nb_bio_with + nb_bioinfo_with + nb_bio_with) < 3) 

```


```{r pre_filter}
# Looking for empty responses or with no empty token
empty_token = c("", "null", "0")
df_enq  <- df_enq %>%
  filter(pmatch(position_title, empty_token) %>% is.na)
```



## Statistiques exploratoires
* Nombre de répondants : `r nrow(df_enq)`
* Réponses fermées
```{r closed_answers_plots, echo=FALSE, fig.height = 12, fig.width = 12}
gender <- ggplot(df_enq, aes(x = gender)) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.9)) +
  ggtitle("Genre")

age <- ggplot(df_enq, aes(x = age)) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.9)) +
  ggtitle("Age")

major_field <- ggplot(df_enq, aes(x = major_field)) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_x_discrete(labels = c("Equilibré", "+ Info", "+ Bio")) +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Dominance dans le travail")

current_loc <- ggplot(df_enq, aes(x = current_loc)) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_x_discrete(labels = c("Étranger (Eur.)", "Étranger (hors Eur.)", "France")) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.9)) +
  ggtitle("Localisation actuelle")

public_private <- ggplot(df_enq, aes(x = public_private)) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.9)) +
  ggtitle("Type d'emploi")

contract <- ggplot(df_enq, aes(x = contract)) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.9)) +
  ggtitle("Type de contrat")

diplome <- ggplot(df_enq, aes(x = diplome)) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.9)) +
  ggtitle("Type de diplôme")

nLab <- c("[15;20[", "[20;25[", "[25;30[", "[30;35[", "[35;40[",
         "[40;45[", "[45;50[", "[50;55[", "[55;60[", "[60;65[",
         "[65;70[", "[70;75[", "[80;++[", "[00;15[")
assign_level <- function(vector, new_levels, missing_level) {
  levels(vector) <- c(new_levels, missing_level)
  return(vector)
}
salary <- ggplot(df_enq %>% mutate(salary = assign_level(salary, nLab, "[75;80[")),
                aes(x = factor(salary, levels = c(nLab, "[75;80[")[c(14,1,2,3,4,5,6,7,8,9,10,11,12,15,13)]))) +
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  scale_x_discrete(drop=FALSE) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.9)) +
  ggtitle("Salaire (en K euro)")

OS <- ggplot(df_enq, aes(x = OS)) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  ylim(0,0.9) +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("OS")
application <- apply(df_enq[, 18:24], 2, function(x){sum(x == "X")}) %>%
  as.data.frame %>% 
  setNames("count") %>%
  mutate(code = rownames(.)) %>%
  mutate(app = c("dev web", "bdd", "scripting", "analyse stat", "sys admin", "dev application", "autre")) %>%
  mutate(prop = count/nrow(df_enq)) 
app <- ggplot(application, aes(x = reorder(app, -prop), y = prop)) +
  geom_bar(stat="identity") +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.9)) +
  ggtitle("Languages context of use")


png("plots/Plot_cat.png", height = 900, width = 1550)
grid.arrange(gender, age, 
             major_field, current_loc,
             public_private, contract,
             salary, diplome, OS, app,
             nrow = 5)
dev.off()

```


* Réponses ouvertes
```{r language_preprocessing_prog}
lang <- paste(df_enq$prog_language, collapse = ",") %>%
  lapply(function(x){gsub(pattern = "\\s", x = x, replacement = ",")}) %>%
  lapply(function(x){gsub(pattern = ";s", x = x, replacement = ",")}) %>%
  lapply(function(x){gsub(pattern = "/", x = x, replacement = ",")}) %>%
  lapply(function(x){gsub(pattern = "\\(", x = x, replacement = ",")}) %>%
  lapply(function(x){gsub(pattern = "\\)", x = x, replacement = ",")}) %>%
  lapply(function(x){gsub(pattern = ",+", x = x, replacement = ",")}) %>%
  lapply(function(x){strsplit(x, split = ",")}) %>%
  as.data.frame %>%
  setNames("word") %>%
  transmute(word = tolower(word)) 

# Using levenshtein distance to merge close language (like with specific version, bad spelling, ...)
lang_lv <- adist(unique(lang$word)) %>% as.data.frame %>% setNames(unique(lang$word))
lang_lv[upper.tri(lang_lv)] <- 999
lang_lv <- which(lang_lv <= 1, arr.ind = TRUE) %>%
  data.frame(w1 = unique(lang$word)[.[,1]],
             w2 = unique(lang$word)[.[,2]]) %>%
  .[,c("w1", "w2")]

# Removing rows where both words are the same
# And excluding when word is too short (<=2). This way, languages with less than 3 letters like R, C, and C# are protected
lang_lv <- lang_lv %>% 
  filter(!(w1 %in% c("c", "r","c#") & w2 %in% c("c", "r","c#"))) %>%
  filter(w1 != w2) %>%
  filter(nchar(as.character(w1)) > 2) %>%
  cbind(truth = c("perl", "python", "python", "python", "bash", "bash", "c++", "c++", "html", "sed", "python", "mysql", "python", "", "")) %>%
  mutate_all(as.character)

# Merging
lang <- lapply(lang$word, function(x){
  if (x %in% lang_lv$w1) {
    return(unique(lang_lv$truth[which(x == lang_lv$w1)]))
  } else if(x %in% lang_lv$w2) {
    return(unique(lang_lv$truth[which(x == lang_lv$w2)]))
  } else {
    return(x)
  }
}) %>% unlist %>% data.frame(prog = ., stringsAsFactors = FALSE)

# Filtering content because there was some sentences and full punctuation words, and merging answer with frequency inferior to 1 into "others"
lang <- lang %>% 
  filter(!(grepl("^[[:punct:]]+$", prog))) %>%
  filter(!(prog %in% stopwords("french"))) %>%
  filter(prog != "") %>%
  left_join(., as.data.frame(table(.$prog)), by = c("prog" = "Var1")) %>%
  mutate(prog = ifelse(Freq < 2,"autre", prog)) %>%
  group_by(prog) %>%
  mutate(Freq = n())

# tab_lang = table(lang$prog) %>% as.data.frame %>% arrange(desc(Freq))
```

```{r language_preprocessing_job}
job <- data.frame(init = df_enq$position_title) %>%
  mutate(init = as.character(init)) %>%
  mutate(cleaned = iconv(init, from = "UTF-8", to = "ASCII//TRANSLIT")) %>%
  mutate(cleaned = removePunctuation(cleaned)) %>%
  mutate(cleaned = tolower(cleaned))

# job_lv <- job$cleaned %>%
#   unique %>%
#   adist %>%
#   as.data.frame() %>%
#   setNames(unique(job$cleaned))

# Corpus 
job_corpus = paste(job$cleaned, collapse = " ") %>%
  lapply(function(x){strsplit(x, split = " ")}) %>%
  unlist %>% data.frame(name = ., stringsAsFactors = FALSE) %>%
  filter(!(name %in% stopwords("french"))) %>%
  filter(!(name == ""))
  
job_table = as.data.frame(table(job_corpus$name))
```

```{r open_answers_plots, echo=FALSE, fig.height = 12, fig.width = 12}
prog <- ggplot(lang , aes(x = reorder(prog, prog, function(x) - table(x)))) + geom_bar(aes(y = (..count..)/sum(..count..))) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Langages de programmation")

png("plots/Plot_prog.png", height = 600, width = 1600)
prog
dev.off()

png("plots/Plot_job.png", height = 500, width = 500)
wordcloud(words = job_table$Var1, freq = job_table$Freq, min.freq = 2,
          random.order = FALSE, colors = brewer.pal(8, "Dark2"))
dev.off()

```


## Analyses comparatives

```{r priv_pub}
gender <- ggplot(df_enq, aes(x = gender, fill = public_private)) + geom_bar(aes(y = (..count..)/sum(..count..)), position=position_dodge()) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Répartition des genres selon public/privé/autre")

diplome <- ggplot(df_enq, aes(x = diplome, fill = public_private)) + geom_bar(aes(y = (..count..)/sum(..count..)), position=position_dodge()) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Type de diplôme selon public/privé/autre")

age <- ggplot(df_enq, aes(x = age, fill = public_private)) + geom_bar(aes(y = (..count..)/sum(..count..)), position=position_dodge()) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Répartition des âges selon public/privé/autre")

contract <- ggplot(df_enq, aes(x = contract, fill = public_private)) + geom_bar(aes(y = (..count..)/sum(..count..)), position=position_dodge()) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Type de contrat selon public/privé/autre")

png("plots/Plot_pub_priv.png", height = 450, width = 1550)
grid.arrange(gender, age, 
             contract, diplome,
             nrow = 2)
dev.off()

```

```{r gender}
diplome <- ggplot(df_enq, aes(x = diplome, fill = gender)) + geom_bar(aes(y = (..count..)/sum(..count..)), position=position_dodge()) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Type de diplôme selon le genre")

age <- ggplot(df_enq, aes(x = age, fill = gender)) + geom_bar(aes(y = (..count..)/sum(..count..)), position=position_dodge()) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Répartition des âges selon le genre")

contract <- ggplot(df_enq, aes(x = contract, fill = gender)) + geom_bar(aes(y = (..count..)/sum(..count..)), position=position_dodge()) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Type de contrat selon le genre")


png("plots/Plot_gender.png", height = 450, width = 1550)
grid.arrange(age, 
             contract, diplome,
             nrow = 2)
dev.off()

```

```{r salary}
salary_contract <- ggplot(df_enq %>% mutate(salary = assign_level(salary, nLab, "[75;80[")),
                aes(x = factor(salary, levels = c(nLab, "[75;80[")[c(14,1,2,3,4,5,6,7,8,9,10,11,12,15,13)]), fill = contract)) +
  geom_bar(aes(y = (..count..)/sum(..count..)), position = position_dodge()) +
  scale_x_discrete(drop=FALSE) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Salaire (en K euro) selon le contrat")

salary_diplome <- ggplot(df_enq %>% mutate(salary = assign_level(salary, nLab, "[75;80[")),
                aes(x = factor(salary, levels = c(nLab, "[75;80[")[c(14,1,2,3,4,5,6,7,8,9,10,11,12,15,13)]), fill = diplome)) +
  geom_bar(aes(y = (..count..)/sum(..count..)), position = position_dodge()) +
  scale_x_discrete(drop=FALSE) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Salaire (en K euro) selon le diplome")

salary_loc <- ggplot(df_enq %>% mutate(salary = assign_level(salary, nLab, "[75;80[")),
                aes(x = factor(salary, levels = c(nLab, "[75;80[")[c(14,1,2,3,4,5,6,7,8,9,10,11,12,15,13)]), fill = current_loc)) +
  geom_bar(aes(y = (..count..)/sum(..count..)), position = position_dodge()) +
  scale_x_discrete(drop=FALSE) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Salaire (en K euro) selon la localisation")

salary_gender <- ggplot(df_enq %>% mutate(salary = assign_level(salary, nLab, "[75;80[")),
                aes(x = factor(salary, levels = c(nLab, "[75;80[")[c(14,1,2,3,4,5,6,7,8,9,10,11,12,15,13)]), fill = gender)) +
  geom_bar(aes(y = (..count..)/sum(..count..)), position = position_dodge()) +
  scale_x_discrete(drop=FALSE) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Salaire (en K euro) selon le genre")

salary_pub_priv <- ggplot(df_enq %>% mutate(salary = assign_level(salary, nLab, "[75;80[")),
                aes(x = factor(salary, levels = c(nLab, "[75;80[")[c(14,1,2,3,4,5,6,7,8,9,10,11,12,15,13)]), fill = public_private)) +
  geom_bar(aes(y = (..count..)/sum(..count..)), position = position_dodge()) +
  scale_x_discrete(drop=FALSE) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Salaire (en K euro) selon public/privé/autre")

salary_major_field <- ggplot(df_enq %>% mutate(salary = assign_level(salary, nLab, "[75;80[")),
                aes(x = factor(salary, levels = c(nLab, "[75;80[")[c(14,1,2,3,4,5,6,7,8,9,10,11,12,15,13)]), fill = major_field)) +
  geom_bar(aes(y = (..count..)/sum(..count..)), position = position_dodge()) +
  scale_x_discrete(drop=FALSE) +
  theme_minimal(base_size = 16) +
  xlab("") +
  ylab("Pourcentage") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Salaire (en K euro) selon la tendance dominante dans le travail")

# salary_ <- ggplot(df_enq %>% mutate(salary = assign_level(salary, nLab, "[75;80[")),
#                 aes(x = factor(salary, levels = c(nLab, "[75;80[")[c(14,1,2,3,4,5,6,7,8,9,10,11,12,15,13)]))) +
#   geom_bar(aes(y = median(year_exp))) +
#   scale_x_discrete(drop=FALSE) +
#   theme_minimal() +
#   xlab("") +
#   ylab("Pourcentage") +
#   ggtitle("Salaire (en K euro) selon public/privé/autre")

png("plots/Plot_salary.png", height = 2000, width = 1550)
grid.arrange(salary_contract, salary_diplome,
             salary_loc, salary_gender,
             salary_pub_priv, salary_major_field,
             nrow = 6)
dev.off()

```





<!-- ```{r semantic_analysis} -->
<!-- corpus_init <- df_enq$position_title -->

<!-- # Syntax study -->
<!-- corpus_formated <- tolower(corpus_init) -->

<!-- # Looking into factors of difference within same words -->
<!-- # https://stackoverflow.com/questions/21511801/text-clustering-with-levenshtein-distances -->
<!-- punctuation_words <- grep("[[:punct:]]", corpus_formated, value = TRUE)  -->
<!-- accent_words <- grep("[À-ÿ]", corpus_formated, value = TRUE, perl = TRUE) -->
<!-- lv_dist <- adist(corpus_formated) # Using leventstein distance to explore word proximity -->
<!-- ggplot(lv_dist %>% .[upper.tri(.)] %>% unlist %>% table %>% as.data.frame %>% mutate_all(as.numeric) %>%  -->
<!--          setNames(c("lv_dist", "freq")), aes(lv_dist, freq)) + geom_line()  -->

<!-- # Cleaning -->
<!-- resume_df = as.data.frame(corpus_formated, stringsAsFactors = FALSE) %>% setNames("init_corpus") %>% -->
<!--   mutate(unpunctuated = removePunctuation(init_corpus)) %>% -->
<!--   mutate(unaccent = iconv(init_corpus, from="UTF-8", to="ASCII//TRANSLIT")) %>% -->
<!--   mutate(un_punc_accent = iconv(unpunctuated, from="UTF-8", to="ASCII//TRANSLIT")) %>% -->
<!--   mutate(un_punc_acc_sw = removeWords(un_punc_accent, stopwords("french"))) -->
<!-- lv_dist_clean <- setNames(as.data.frame(adist(unique(resume_df$un_punc_accent))), unique(resume_df$un_punc_accent)) # Using leventstein distance to explore word proximity -->
<!-- h = hclust(as.dist(lv_dist_clean)) -->
<!-- ggplot(lv_dist_clean %>% .[upper.tri(.)] %>% unlist %>% table %>% as.data.frame %>% mutate_all(as.numeric) %>%  -->
<!--          setNames(c("lv_dist_clean", "freq")), aes(lv_dist_clean, freq)) + geom_line()  -->
<!-- lv_dist_clean[upper.tri(lv_dist_clean)] = 999 -->
<!-- close_words_ind <- which(lv_dist_clean < 6, arr.ind = TRUE) -->
<!-- close_words <- data.frame(w1 = resume_df$un_punc_accent[close_words_ind[,1]],  -->
<!--                           w2 = resume_df$un_punc_accent[close_words_ind[,2]]) -->

<!-- ######### TEST  -->

<!-- #########  -->
<!-- # tree = hclust(lv_dist) -->
<!-- wss <- (nrow(lv_dist)-1)*sum(apply(lv_dist,2,var)) -->
<!-- for (i in 2:40) wss[i] <- sum(kmeans(lv_dist, centers=i)$withinss) -->
<!-- plot(1:40, wss, type="b", xlab="Number of Clusters",ylab="Within groups sum of squares")  -->
<!-- ######### -->

<!-- word_low_lv = data.frame(word_1 = character(), word_2 = character(), lv_dist = numeric(), stringsAsFactors = FALSE) -->
<!-- for (i in 1:nrow(lv_dist)) { -->
<!--   for (j in 1:ncol(lv_dist)) { -->
<!--     if (lv_dist[i,j] > 0 & lv_dist[i,j] < 5) { -->
<!--       word_low_lv[nrow(word_low_lv) + 1,] <- c(corpus_formated[i], corpus_formated[j], lv_dist[i,j]) -->
<!--     } -->
<!--   } -->
<!-- } -->

<!-- ``` -->
